import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from sklearn.model_selection import train_test_split

# ============================
# 1. æž„é€ ç”Ÿæ´»é£Ÿç‰©æ•°æ®
# ============================
foods = [
    "è‹¹æžœ", "é¦™è•‰", "è¥¿çº¢æŸ¿", "èƒ¡èåœ", "é¸¡èƒ¸è‚‰", "è¥¿å…°èŠ±", "é…¸å¥¶",
    "è–¯æ¡", "ç‚¸é¸¡", "å¯ä¹", "æ±‰å ¡", "é¥¼å¹²", "è›‹ç³•", "å·§å…‹åŠ›"
]

labels = [
    0,0,0,0,0,0,0,   # å¥åº· 0
    1,1,1,1,1,1,1    # ä¸å¥åº· 1
]

label_name = ["å¥åº·ðŸ¥—","ä¸å¥åº·ðŸŸ"]

# ============================
# 2. Tokenizer æ–‡æœ¬æ•°å­—åŒ–
# ============================
tokenizer = Tokenizer()
tokenizer.fit_on_texts(foods)

X = tokenizer.texts_to_sequences(foods)
X = pad_sequences(X, maxlen=3)
y = np.array(labels)

# ============================
# 3. LSTM åˆ†ç±»æ¨¡åž‹
# ============================
model = Sequential([
    Embedding(input_dim=50, output_dim=16, input_length=3),
    LSTM(32),
    Dense(1, activation="sigmoid")
])

model.compile(optimizer="adam",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# ============================
# 4. è®­ç»ƒ
# ============================
model.fit(X, y, epochs=50, verbose=0)
print("è®­ç»ƒå®Œæˆ âœ”")

# ============================
# 5. é¢„æµ‹å‡½æ•°
# ============================
def classify_food(name):
    seq = tokenizer.texts_to_sequences([name])
    seq = pad_sequences(seq, maxlen=3)
    pred = model.predict(seq)[0][0]
    return label_name[1 if pred>0.5 else 0]

# æµ‹è¯•
print(classify_food("è‹¹æžœ"))
print(classify_food("ç‚¸é¸¡"))
print(classify_food("é…¸å¥¶"))
print(classify_food("è›‹ç³•"))
